# Production Optuna Hyperparameter Optimization Configuration
# Note: Output paths (mlflow, predictions, visualizations, best_params) are automatically
# managed by RunManager when using run_production_evaluation.py. They are organized in
# timestamped folders under results/runs/{timestamp}_{name}/.

# Data Source Configuration - Production paths with FFV1 format
data_source:
  base_data_path: "./data/SD_02_SURF_FOOTAGE_PREPT"
  video_clips:
    h264_path: "03_CLIPPED/h264"
    ffv1_path: "03_CLIPPED/ffv1"
    input_format: "h264" # Production uses ffv1 format
  annotations:
    labels_path: "04_ANNOTATED/EXPORTED-MANEUVER-LABELS"
    maneuver_annotations_file: "maneuver_annotations.json"
    sony_300_labels: "sony_300"
    sony_70_labels: "sony_70"
  splits:
    train_ratio: 0.70
    val_ratio: 0.15
    test_ratio: 0.15
    random_seed: 42
    zoom_handling:
      enabled: true
      balanced_distribution: true
      force_no_zoom_in_val: true
  camera_selection:
    enabled_cameras: ["SONY_300", "SONY_70"] # Use both cameras for robust optimization
    max_clips_per_session: 60 # Reasonable subset for optimization speed

# Model Configuration
models:
  mediapipe:
    config_path: "configs/model_configs/mediapipe.yaml"
  blazepose:
    config_path: "configs/model_configs/blazepose.yaml"
  yolov8_pose:
    config_path: "configs/model_configs/yolov8_pose.yaml"
  pytorch_pose:
    config_path: "configs/model_configs/pytorch_pose.yaml"
  mmpose:
    config_path: "configs/model_configs/mmpose.yaml"

# Evaluation Configuration
evaluation:
  quick_test:
    enabled: true
    num_clips: 25 # Increased for better optimization signal
    models: ["yolov8_pose", "pytorch_pose", "mmpose"] # Fast model for quick validation
  comprehensive_test:
    enabled: true
    num_clips: 50 # Optimized for efficient consensus-based validation
    models: ["mediapipe", "blazepose", "yolov8_pose", "pytorch_pose", "mmpose"]

# Optuna Optimization
optuna:
  enabled: true
  study_name: "surf_pose_optimization_production"
  direction: "maximize" # Maximize PCK accuracy
  n_trials: 100 # Balanced optimization with pre-generated consensus
  timeout_minutes: 300 # 5 hours max per model
  sampler: "TPESampler"
  pruner: "MedianPruner"

  # Intelligent early stopping configuration (optimized based on test results)
  early_stopping:
    enabled: true
    patience: 10 # Stop if no improvement for 10 trials
    min_trials: 30 # Minimum trials before early stopping (increased for better exploration)
    improvement_threshold: 0.001 # Minimum improvement to continue
    plateau_threshold: 0.95 # Consider plateaued if within 95% of best

  # Model-specific optimization settings (optimized based on test performance)
  model_settings:
    mediapipe:
      expected_trials: 20 # Fast model, fewer trials needed
      patience: 8
    yolov8_pose:
      expected_trials: 25
      patience: 10
    blazepose:
      expected_trials: 30
      patience: 12
    mmpose:
      expected_trials: 40 # Complex model, more trials
      patience: 15
    pytorch_pose:
      expected_trials: 35
      patience: 12

# Optuna Validation Configuration
optuna_validation:
  # Use consensus-based pseudo-ground-truth for validation
  use_consensus: true

  # Number of clips for Optuna optimization
  num_clips: 50

  # Cameras to use for Optuna (both cameras for robust optimization)
  cameras:
    - SONY_300
    - SONY_70

  # Ensure no overlap with comparison validation set
  ensure_no_overlap_with_comparison: true

# Models to optimize
models_to_optimize:
  - yolov8
  - pytorch_pose
  - mmpose
  - mediapipe
  - blazepose

# Consensus configuration reference
consensus_config: configs/consensus_config.yaml

# Consensus Cache Configuration - Smart automatic reuse
consensus_cache:
  # Automatically discover and reuse cache from most recent complete run
  auto_reuse: true # Set to false to always regenerate

  # Optional: manually specify cache directory (if null, auto-discover from results/runs/)
  cache_dir: null

  # If no cache found or auto_reuse=false, regenerate with these params
  regenerate_params_source: "defaults" # "best_params", "file", or "defaults"
  regenerate_params_file: null

# Performance Configuration (Production optimized)
performance:
  max_workers: 8 # Full utilization for production
  batch_size: 1
  device: "auto" # Auto-detect: CUDA first, then MPS/CPU
  memory_limit_gb: 28 # Reduced to leave headroom for memory profiling
  enable_gpu_memory_growth: true
  half_precision: true # Enable FP16 for RTX 4090

# Minimal configuration for direct usage with evaluate_pose_models.py
# (RunManager will override these with proper paths when using run_production_evaluation.py)
mlflow:
  enabled: true
  experiment_name: "surf_pose_production_optuna"

output:
  predictions:
    enabled: false # DISABLED during Optuna optimization for speed
  visualization:
    enabled: false # DISABLED during Optuna optimization for speed

# Reference configurations (commented out - handled by RunManager or rarely changed)
#
# experiment:
#   name: "surf_pose_production_optuna"
#   description: "Hyperparameter optimization for pose estimation models"
#   version: "1.0"
#   author: "Production Team"
#
# dataset:
#   base_data_path: "./data/SD_02_SURF_FOOTAGE_PREPT"
#   video_clips:
#     input_format: "ffv1"  # Production uses ffv1 format
#   annotations:
#     labels_path: "04_ANNOTATED/EXPORTED-MANEUVER-LABELS"
#   splits:
#     train_ratio: 0.70
#     val_ratio: 0.15
#     test_ratio: 0.15
#     random_seed: 42
#
# hardware:
#   gpu:
#     device_id: 0
#     memory_fraction: 0.9
#     allow_growth: true
#   cpu:
#     num_workers: 8
#     num_threads: 16
#   memory:
#     max_memory_gb: 32
#     cache_enabled: true
#     clear_cache_frequency: 50
#
# logging:
#   level: "INFO"
#   format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
#   save_to_file: true
#
# debug:
#   enabled: false
#   save_intermediate_results: false
#   profile_memory: false
#   profile_compute: false
#   verbose_errors: true
